{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d3b5c0-eec5-4836-ac22-c16cd22a6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6d2e5f-a1bd-470f-ba89-6d5bdffd82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('./data/tower_prep_data_csv.csv', delimiter=',', dtype=np.float32, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c97ec9-344e-466d-839a-b6baad215cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.88 19.88 19.88 ... 22.   22.   22.  ]\n"
     ]
    }
   ],
   "source": [
    "temperature = data[:, 5]\n",
    "print(temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835b5eec-97e2-4dbb-aad5-dcddbdea4f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 15000 #math.ceil(len(temperature) * 0.8)\n",
    "train_data = temperature[: -size]\n",
    "test_data = temperature[-size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2777f7d-4046-4ce6-89ab-0f2c4201a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data .reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec3f8c67-cf51-46fa-bfa3-2f0a904d968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ceead8-20ed-4cfa-bac0-849a03481759",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f37a5772-f773-4835-997a-ce16546021b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f07926d-693b-4ce0-a4cb-bea6d6ebe349",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(train_data_normalized, train_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4122db28-ed13-4546-8c5e-ace92c39b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=20, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, 1)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d54808-fb85-4c0f-8a7a-2828eacbde30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a75e56-e28d-4bac-b73c-3d391e5a2ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04095158]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "\n",
    "    #train_window = 20000 - i * 1000\n",
    "    fut_pred = 1000\n",
    "\n",
    "    test_inputs = train_data_normalized[-train_window:].tolist()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(fut_pred):\n",
    "        seq = torch.FloatTensor(test_inputs[-train_window:])\n",
    "        with torch.no_grad():\n",
    "            model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, model.hidden_layer_size))\n",
    "            test_inputs.append(model(seq).item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:] ).reshape(-1, 1))\n",
    "    #print(actual_predictions)\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(fut_pred):\n",
    "\n",
    "        sum += abs(actual_predictions[i] - test_data[i]) / test_data[i]\n",
    "\n",
    "    accuracy = sum / fut_pred\n",
    "    print(accuracy)\n",
    "    \n",
    "    plt.title('Month vs Passenger')\n",
    "    plt.ylabel('Total Passengers')\n",
    "    plt.grid(True)\n",
    "    plt.autoscale(axis='x', tight=True)\n",
    "    plt.plot(test_data[:fut_pred])\n",
    "    plt.plot(actual_predictions)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "424ab126-6c40-4e3a-933c-dd837e069b65",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-216dad128fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                             torch.zeros(1, 1, model.hidden_layer_size))\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0msingle_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-0791971b5d92>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    680\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "accuracy = 1\n",
    "\n",
    "while(accuracy > 0.005):\n",
    "    for i in range(epochs):\n",
    "        for seq, labels in train_inout_seq:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "            y_pred = model(seq)\n",
    "\n",
    "            single_loss = loss_function(y_pred, labels)\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "    \n",
    "    \n",
    "\n",
    "    fut_pred = 1000\n",
    "\n",
    "    test_inputs = train_data_normalized[-train_window:].tolist()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(fut_pred):\n",
    "        seq = torch.FloatTensor(test_inputs[-train_window:])\n",
    "        with torch.no_grad():\n",
    "            model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, model.hidden_layer_size))\n",
    "            test_inputs.append(model(seq).item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:] ).reshape(-1, 1))\n",
    "    #print(actual_predictions)\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(fut_pred):\n",
    "\n",
    "        sum += abs(actual_predictions[i] - test_data[i]) / test_data[i]\n",
    "\n",
    "    accuracy = sum / fut_pred\n",
    "    print(accuracy)\n",
    "    \n",
    "    plt.title('Month vs Passenger')\n",
    "    plt.ylabel('Total Passengers')\n",
    "    plt.grid(True)\n",
    "    plt.autoscale(axis='x', tight=True)\n",
    "    plt.plot(test_data[:fut_pred])\n",
    "    plt.plot(actual_predictions)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64d239c3-8446-49ec-8f6b-f5a6e8e44cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./models/pir.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7fdc67-1711-4696-9e1e-e9a74dc6f93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
